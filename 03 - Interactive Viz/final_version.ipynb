{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choropleth Map\n",
    "The goal of this homework is to build a [choropleth map](https://en.wikipedia.org/wiki/Choropleth_map) showing how much research funding goes to each Swiss canton. We use the [P3 database](http://p3.snf.ch/) from the Swiss National Science Foundation. Since the data only contain the names of universities, we need to map each university to a location – and more specifically a canton. To this end, we use the Google Places and Google Geocoding APIs. Finally the map is created in Javascript using the [Leaflet](http://leafletjs.com/) library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data\n",
    "We get the data from the CSV file. In German, the text *Nicht zuteilbar - NA* means that there are no data so we specify we want the NaN value instead. We also specify that the index should be the *Project number* column. As seen below this index is unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('P3_GrantExport.csv', sep=';', index_col=0, na_values=['Nicht zuteilbar - NA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.index.is_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locations of universities\n",
    "As seen below, the names of universities often contains a dash followed by the short name of the institute. To get more accurate results when using the Google API, we want to be able to remove this part of the name. The `trim_university_name(full_name)` function extracts only the first part of the university name.\n",
    "\n",
    "We also define a `search_uni(university_name)` function which returns a tuple containing the canton the university is in, the latitude and the longitude. The canton name is represented with two letters (e.g. GE for Geneva). All of these functions are defined in the utils.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import trim_university_name, search_uni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, we can get the location of EPFL. Please keep in mind that you need a Google API key to use the `search_uni()` function. The key has to be in a JSON file named `google_api_key.json`, associated with the `api_key` key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search_uni(trim_university_name('Ecole Polytechnique Fédérale de Lausanne - EPFL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to create a CSV file containing the list of all universities that receive funding with their associated location and canton. First we create a series containing the names of all universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_names = df.University.drop_duplicates().dropna()\n",
    "uni_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset contains 76 universities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uni_names.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we want to associate each university to its location. We create a dictionary containing this mapping that we use to create a Pandas dataframe. **Executing this cell sends a lot of requests to the Google API, you may prefer to skip it and load the CSV in the next cell!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#uni_infos = {uni: search_uni(trim_university_name(uni)) for uni in uni_names}\n",
    "#uni_data = uni_names.map(lambda s: uni_infos[s] if uni_infos[s] is not None else (np.nan,) * 3)\n",
    "#unis = pd.DataFrame(uni_data.tolist(), columns=['canton', 'latitude', 'longitude'], index=uni_names)\n",
    "#unis.index.name = 'name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data from the CSV file (useful to avoid requesting all the data from Google if we already did it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unis = pd.read_csv('universities.csv', index_col='name')\n",
    "unis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unis.to_csv('universities.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we miss the location of 16 universities. We'll add the data manually. Note that some entries do not correspond to a specific place. For instance *weitere Institute* means other institutes and the first row corresponds to several libraries and museums. We'll leave these entries empty to exclude them from the analysis since we can't associate them to a specific canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "missing_loc = unis[unis.isnull().any(axis=1)]\n",
    "print('There are {} entries without location data.'.format(len(missing_loc)))\n",
    "missing_loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "additional_data = {\n",
    "    'Physikal.-Meteorolog. Observatorium Davos - PMOD': ('GR', 46.8133161, 9.8422335),\n",
    "    'Swiss Center for Electronics and Microtech. - CSEM': ('NE', 46.997778, 6.9453443),\n",
    "    'Fachhochschule Nordwestschweiz (ohne PH) - FHNW': ('SO', 47.348146, 7.9056693),\n",
    "    'Swiss Institute of Bioinformatics - SIB': ('VD', 46.5205653, 6.5721676),\n",
    "    'Forschungskommission SAGW': ('BE', 46.94727, 7.4344473),\n",
    "    'Pädag. Hochschule Tessin (Teilschule SUPSI) - ASP': ('TI', 46.02351, 8.9149293),\n",
    "    'Schweizer Kompetenzzentrum Sozialwissensch. - FORS': ('VD', 46.5254827, 6.5784405),\n",
    "    'Staatsunabh. Theologische Hochschule Basel - STHB': ('BS', 47.581238, 7.6479233)\n",
    "}\n",
    "new_df = pd.DataFrame.from_dict(additional_data, orient='index')\n",
    "new_df.columns = ['canton', 'latitude', 'longitude']\n",
    "unis.update(new_df) # Replace old data in the original dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 8 remaining entries could not be associated with a specific canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "missing_loc = unis[unis.isnull().any(axis=1)]\n",
    "len(missing_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also notice that some universities aren't located in Switzerland (e.g. the Istituto Svizzero di Roma). And thus we can ignore them since they aren't associated with any canton. We also remove the NaN values at the same time since we already said we couldn't associate them to any canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "swiss_cantons = ['ZH', 'BE', 'LU', 'UR', 'SZ', 'OW', 'NW', 'GL', 'ZG', 'FR', 'SO', 'BS', 'BL',\n",
    "                 'SH', 'AR', 'AI', 'SG', 'GR', 'AG', 'TG', 'TI', 'VD', 'VS', 'NE', 'GE', 'JU']\n",
    "unis = unis[unis.canton.isin(swiss_cantons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amount per canton\n",
    "First, we create a new dataframe containing, for each project, the amount and the university. We need to convert the *amount* column to a numeric type since it's loaded from the CSV as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "amounts = df[['University', 'Approved Amount']]\n",
    "amounts = amounts.rename(columns={'University': 'university', 'Approved Amount': 'amount'})\n",
    "amounts.index.name = 'project'\n",
    "amounts.amount = pd.to_numeric(amounts.amount, errors='coerce')\n",
    "amounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge the two dataframes to also get the associated canton for each project. Finally, we can group by canton and sum to get the total amount of funding per canton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amounts = amounts.merge(unis[['canton']], left_on='university', right_index=True, how='right')\n",
    "amounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "amounts = amounts.groupby('canton').sum()\n",
    "amounts = amounts.amount # The dataframe has only one column so we extract it to get a Pandas series\n",
    "amounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell makes sure all the Swiss cantons are in the `canton` series. We set the amount to 0 for the cantons that were missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amounts = amounts.reindex(pd.Series(swiss_cantons)).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the map\n",
    "We build directly the map in Javascript using Leaflet insteaf of using Folium – which is a wrapper in Python around Leaflet. Our Javascript script is called `leaflet.js` and is located in the `js` folder.\n",
    "\n",
    "We decided to use 6 classes to build our choropleth map since this we noticed that using more than 6 makes it harder to spot the differences between non-ajdacent cantons. The map is interactive: you can hover a canton to show the absolute amount of funding, you can also choose whether to display the universities or not, it is also possible to show a line indicating the Röstigraben location. Moreover, we converted the TopoJSON file containing the Swiss cantons geometry to the GeoJSON format since Leaflet doesn't support the TopoJSON format. We chose the color for our 6 classes using [ColorBrewer](http://colorbrewer2.org).\n",
    "\n",
    "To chose split our data in 6 classes, we created the `linear_split(nb_classes)` function. It chooses the thresholds using the quantiles such that each class containts the same number of cantons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_split(nb_classes):\n",
    "    min_value = amounts.min()\n",
    "    max_value = amounts.max()\n",
    "    split = (max_value - min_value) / nb_classes\n",
    "    return [round(amounts.min() + i * split) for i in range(1, nb_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def quantile_split(nb_classes):\n",
    "    return [round(amounts[amounts > 0].quantile(i/nb_classes)) for i in range(1, nb_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our data available to our JS script, we export it to a *data.js* file which we load in the HTML page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_data(split_function):\n",
    "    with open('js/data.js', 'w') as f:\n",
    "        f.write('var universities = {}\\n'.format(unis.reset_index().to_json(orient='records')))\n",
    "        f.write('var cantons = {}\\n'.format(amounts.to_json()))\n",
    "        f.write('var scale = {}'.format(split_function(6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the result below. Please note that the map won't show in the preview made by GitHub. You should clone the repository and either reevaluate the cells below or, after calling the `export_data()` function to choose which scale you want, open directly this [HTML page](leaflet.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantiles scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_data(quantile_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\">\n",
    "<iframe src=\"leaflet.html\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;\"></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "export_data(linear_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\">\n",
    "<iframe src=\"leaflet.html\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;\"></iframe></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Röstigraben\n",
    "Here we're interested in the repartition of funds between the two sides of the röstigraben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
