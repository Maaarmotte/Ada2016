{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "#import community\n",
    "\n",
    "# To make the figures look nice and large\n",
    "plt.rcParams['figure.figsize'] = (40.0, 30.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Wordclouds\n",
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"hillary-clinton-emails/Emails.csv\")\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we inspect what data we are given. For the wordcloud it would be wise to use only the \"ExtractedBodyText\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing emails without body text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails.size #Size of the dataset before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = emails[pd.notnull(emails['ExtractedBodyText'])]\n",
    "emails.size #Size of the dataset after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generating the wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Converting the ExtractedBodyText into strings we can use for the wordcloud. Note that we tell WordCloud to not remove any stopwords for this first graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = emails.ExtractedBodyText.to_string();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(stopwords=['']).generate(text)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the wordcloud we will go through the process of removing stopwords. Then we will make sure to have only alphabetical characters and use stemming to convert words into their original base form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text) # Tokenizing the text\n",
    "    tokens = [i for i in tokens if i.isalpha()] #Keeping only strings with alphabetic characters\n",
    "    tokens = [i for i in tokens if i.lower() not in sw] #Removing stopwords\n",
    "    stems = stem_tokens(tokens, stemmer) #Stemming the words\n",
    "    return stems  #returns a list\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "improvedText = str(tokenize(text)).replace(\"'\", \"\") #Convert from list to string object without single quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(improvedText)\n",
    "plt.imshow(wc)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When comparing the two wordclouds, we see that they are very different. In the first cloud we have all the stopwords, which means the wordcloud does not show us any indication of some specific characteristics of Hillary Clinton emails.  In the second cloud some words are shortened to their stems such as 'Novemb' and 'relea'. The stopwords are removed, so we see a better representation of the most common words used in the emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sentiment analysis\n",
    "First, let's see which countries we can find in the emails corpus using the `lookup()` method of pycountry. It looks for any reference to a country, i.e. its full name, its official name or its two or three letters code. The search is **not** case sentitive. We tokenize each email and look if a token matches a country. There is a major problem with this approach, if a country name contains multiple words (e.g. Ivory Coast or Hong Kong), it won't be detected. However it allows us to identify another issue that we'll discuss below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pycountry\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "countries = []\n",
    "\n",
    "for text in df.ExtractedBodyText.dropna():\n",
    "    text = text.lower()\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in stopwords:\n",
    "            try:\n",
    "                country = pycountry.countries.lookup(token)\n",
    "                countries.append(country.name)\n",
    "            except LookupError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_countries = pd.Series(countries)\n",
    "df_countries.value_counts().sort_values(ascending=False).head(20).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen on the previous plot, there are some countries that are over represented, especially given their small size. For instance St Pierre and Miquelon or Micronesia. This is because their 2 letter codes are PM and FM which stand for Prime Minister and Foreign Minister. Moreover PM is also used for time notation. Because of this, we chose not to use 2 and 3 letters codes. We could have used a white or blacklist but there is no way to be sure we don't miss or match too many countries.\n",
    "\n",
    "Our final method to detect mentions is the following: for each email we loop over every country and check if there is a match with the content of the email. To do this we use a case insensitive regular expression to detect if the usual or official name of a country is present as a word in the document (can't be just a part of a word because of countries like Oman which would match the word 'woman'). We also created a python dictionary to override some of the names (only for the common names, not for the official ones) given by the pycountry library because they were overly complicated and did not match the name people usually use.\n",
    "\n",
    "For each email we also analyze its content to get a score representing the sentiment associated with the text. We add this score in a dictionnary for each country mentioned in the text. At the end we average the score of each country. The first example uses the VADER sentiment analysis tools.\n",
    "\n",
    "*Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dict = {\n",
    "    \"Bolivia, Plurinational State of\": \"Bolivia\",\n",
    "    \"Bosnia and Herzegovina\": \"Bosnia\",\n",
    "    \"Bonaire, Sint Eustatius and Saba\": \"Caribbean Netherlands\",\n",
    "    \"Brunei Darussalam\": \"Brunei\",\n",
    "    \"Micronesia, Federated States of\": \"Micronesia\",\n",
    "    \"Falkland Islands (Malvinas)\": \"Falkland Islands\",\n",
    "    \"Micronesia, Federated States of\": \"Micronesia\",\n",
    "    \"Iran, Islamic Republic of\": \"Iran\",\n",
    "    \"Korea, Republic of\": \"South Korea\",\n",
    "    \"Lao People's Democratic Republic\": \"Laos\",\n",
    "    \"Saint Martin (French part)\": \"Saint Martin\",\n",
    "    \"Moldova, Republic of\": \"Moldova\",\n",
    "    \"Macedonia, Republic of\": \"Macedonia\",\n",
    "    \"Korea, Democratic People's Republic of\": \"North Korea\",\n",
    "    \"Palestine, State of\": \"Palestine\",\n",
    "    \"Russian Federation\": \"Russia\",\n",
    "    \"Saint Helena, Ascension and Tristan da Cunha\": \"Saint Helena\",\n",
    "    \"Svalbard and Jan Mayen\": \"Svalbard\",\n",
    "    \"Sint Maarten (Dutch part)\": \"Sint Maarten\",\n",
    "    \"Syrian Arab Republic\": \"Syria\",\n",
    "    \"Taiwan, Province of China\": \"Taiwan\",\n",
    "    \"Tanzania, United Republic of\": \"Tanzania\",\n",
    "    \"Holy See (Vatican City State)\": \"Vatican\",\n",
    "    \"Venezuela, Bolivarian Republic of\": \"Venezuela\",\n",
    "    \"United States Minor Outlying Islands\": \"US Virgin Islands\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pycountry\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def sentiment_per_country(scoring_function):\n",
    "    # scoring_function is a function taking text as input and returning a score between -1 and 1\n",
    "    # -1 is negative, 1 is positive\n",
    "    \n",
    "    countries = defaultdict(list)\n",
    "    \n",
    "    for text in df.ExtractedBodyText.dropna():\n",
    "        polarity_score = scoring_function(text)\n",
    "\n",
    "        for country in pycountry.countries:\n",
    "            name = name_dict.get(country.name, country.name)\n",
    "            try:\n",
    "                regex = r'\\b(?:{}|{})\\b'.format(name, country.official_name)\n",
    "            except AttributeError: # Not all countries have an official name field\n",
    "                regex = r'\\b{}\\b'.format(name)\n",
    "    \n",
    "            if re.search(regex, text, re.IGNORECASE):\n",
    "                countries[name].append(polarity_score)\n",
    "    \n",
    "    return countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "countries = sentiment_per_country(lambda t: vader.polarity_scores(t)['compound'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the plot of the average sentiment associated with each country mentionned in the emails. The score goes from -1 to 1, -1 being the most negative and 1 being the most positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_map(score, color_scheme):\n",
    "    # score is expected to be between -1 and 1\n",
    "    index = (score + 1) / 2 * (len(color_scheme) - 1) # map the score to a color\n",
    "    return color_scheme[round(index)]\n",
    "\n",
    "def plot_scores(countries):\n",
    "    scores = pd.DataFrame.from_dict(countries, orient='index').mean(axis=1).sort_values()\n",
    "    df_countries = pd.DataFrame({'score': scores})\n",
    "    df_countries['color'] = df_countries.score.apply(lambda x: color_map(x, ['#d73027','#fc8d59','#fee08b','#d9ef8b','#91cf60','#1a9850']))\n",
    "\n",
    "    df_countries.score.plot(figsize=(15, 50), kind='barh', grid=True, width=0.7, color=df_countries.color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_scores(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use Liu and Hu opinion lexicon to compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.util import demo_liu_hu_lexicon\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "def liu_hu_score(text):\n",
    "    out = io.StringIO()\n",
    "    with redirect_stdout(out):\n",
    "        demo_liu_hu_lexicon(text)\n",
    "    \n",
    "    s = out.getvalue().rstrip()\n",
    "    if s == 'Positive':\n",
    "        polarity_score = 1\n",
    "    elif s == 'Negative':\n",
    "        polarity_score = -1\n",
    "    else:\n",
    "        polarity_score = 0\n",
    "        \n",
    "    return polarity_score\n",
    "\n",
    "countries = sentiment_per_country(liu_hu_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_scores(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the models.ldamodel module from the gensim library, run topic modeling over the corpus. Explore different numbers of topics (varying from 5 to 50), and settle for the parameter which returns topics that you consider to be meaningful at first sight.\n",
    "\n",
    "Start by important gensim libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim import corpora\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data, keep only the ExtractedBodyText cells and remove null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails = pd.DataFrame(pd.read_csv('hillary-clinton-emails/Emails.csv')['ExtractedBodyText'].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use the same functions defined in the first exercice to remove the stopwords, remove numbers and stem tokens. Note that we also lower all tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails['ExtractedBodyText'] = emails.ExtractedBodyText.apply(lambda x: [word.lower() for word in tokenize(x) if word not in sw])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the tokenized emails into a list of lists of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = emails.ExtractedBodyText.tolist()\n",
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the list of lists of tokens into a corpus (a list of Bag of Words), and then train the Latent Dirichlet Allocation model on the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, make a function to print the topics in a concise way, for a better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_topics(topics):\n",
    "    for topic in topics:\n",
    "        print(\"Topic {}:\\t\".format(topic[0]), end=\"\")\n",
    "        for tup in topic[1]:\n",
    "            print(\"{}, \".format(tup[0], tup[1]), end=\"\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to find 5 topics in the corpus using the Latent Dirichlet Allocation model. Note that running the algorithm can take a bit of time, due to the number of passes. To avoid having to train the model multiple times, the topics are stored in two files. It is also better to discuss to topics, because they are not exactly the same between multiple runs. Increasing the number of passes (default is 1) is good because it increases accuracy of topic modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pickle.load(open('5_topics.p', 'rb'))\n",
    "except:\n",
    "    model = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=50)\n",
    "    data = model.show_topics(num_topics=5, num_words=10, formatted=False)\n",
    "    pickle.dump(data, open('5_topics.p', 'wb'))\n",
    "\n",
    "format_topics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the topics are generic. They are about Obama, diplomacy and politics in general. For example, topic 0 is about elections ('elect', 'vote') and american politics ('democrat', 'republican', 'parti', 'senat'). We can compare these topics with the one generated by the LDA model when looking for 50 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pickle.load(open('50_topics.p', 'rb'))\n",
    "except:\n",
    "    model = LdaModel(corpus, num_topics=50, id2word=dictionary, passes=50)\n",
    "    data = model.show_topics(num_topics=50, num_words=10, formatted=False)\n",
    "    pickle.dump(data, open('50_topics.p', 'wb'))\n",
    "    \n",
    "format_topics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, they are more diverse. Instead of having one topic for diplomacy, we have one topic about pakistan (27), one about china (24), one about israel and palestinia (7), etc. There are also topics about recent events: North Korea testing nuclear weapons (27), attack in Benghazi (26), etc. We could say that 50 topics is too much because some topics seem to be not related to anything (2, 49, ...), but it is not necessarily true since some topics (Russia for example) do not appear at each run of the LDA model. Note that his can also be because the word 'Russia' is not important enough to be in the top ten words of any topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pickle.load(open('25_topics.p', 'rb'))\n",
    "except:\n",
    "    model = LdaModel(corpus, num_topics=25, id2word=dictionary, passes=50)\n",
    "    data = model.show_topics(num_topics=25, num_words=10, formatted=False)\n",
    "    pickle.dump(data, open('25_topics.p', 'wb'))\n",
    "    \n",
    "format_topics(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When limited to 25, the topics are more centered around US politics ('democrat', 'republican', 'vote', 'elect', 'senat', 'bill', 'parti', 'presid', ...), meetings ('call', 'talk', 'tomorrow', 'work', 'offic', 'meet', 'room', ...) and middle east ('iran', 'israel', 'border', 'jewish', 'palestinian', 'ahmadinejad', 'peac', ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best number of topics to look for actually depends on how deep a person wants to go. If set to 5, then only generic topics will emerge with not much information, and it probably won't be enough for most cases. With 50, more detailed topics appear, specialized for different countries the US are working with. But with these also come less meaningful topics. A good compromise would be to find a value between 5 and 25. For example, with 25, the topics are not too generic, and there aren't too much missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Bonus - Communication graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First we are going to load the data and select columns, which are relevant for the task. For the communication graph it does not matter whether there was any text in the email or not, so we don't remove rows with NaN for 'ExtractedBodyText'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emails = pd.read_csv(\"hillary-clinton-emails/Emails.csv\")\n",
    "emails = emails[pd.notnull(emails['SenderPersonId'])]\n",
    "emails = emails[['Id', 'SenderPersonId', 'ExtractedBodyText']]\n",
    "emails.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the table 'persons' has multiple IDs for the same persons, because they can have different email addresses, then we decided to eliminate rows, where the name was given as an email address. We assume that people who wrote more emails were identified by a name instead of an email address. Thanks to this we got rid of some duplicates in the network graph and reduced the number of nodes from 468 to 324."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "persons = pd.read_csv(\"hillary-clinton-emails/Persons.csv\")\n",
    "persons = persons[~persons.Name.str.contains('@')]\n",
    "persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "receivers = pd.read_csv(\"hillary-clinton-emails/EmailReceivers.csv\", index_col =0)\n",
    "receivers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By merging the 'receivers' with persons, we are able to match the person IDs with the given name of the person. We do the same for the senders of the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reWithNames = pd.merge(receivers, persons, how='outer', left_on= 'PersonId', right_on= 'Id')\n",
    "reWithNames = reWithNames[['EmailId','PersonId','Name']]\n",
    "reWithNames = reWithNames.rename(columns={'Name': 'Receiver'})\n",
    "reWithNames.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seWithNames = pd.merge(emails, persons, how='outer', left_on= 'SenderPersonId', right_on= 'Id')\n",
    "seWithNames = seWithNames.rename(columns={'Name': 'Sender'})\n",
    "seWithNames.drop('Id_y', axis=1, inplace=True)\n",
    "seWithNames.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can combine the senders and receivers into one dataframe by matching the email IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "newDF = pd.merge(seWithNames, reWithNames, how='outer', left_on= 'Id_x', right_on= 'EmailId')\n",
    "newDF = newDF[pd.notnull(newDF['SenderPersonId'])]\n",
    "newDF = newDF[pd.notnull(newDF['PersonId'])]\n",
    "newDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the network graph from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "G=nx.from_pandas_dataframe(newDF, 'Sender', 'Receiver', create_using=nx.Graph())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos=nx.spring_layout(G) # Positions for all nodes\n",
    "nx.draw(G, with_labels=True, alpha=0.6,node_color='salmon', edge_color='darkgrey', font_size=17)\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "plt.savefig(\"communication-graph.png\") # Save as png for closer view\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "G.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the network graph we see that most emails are connected with Hillary Clinton as expected. Nevertheless there are other people who are also forming communities of connection. For example Cheryl Mills, Huma Abedin and Jake Sullivan. When researching about these people we find that they were close advisors of Hillary Clinton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
